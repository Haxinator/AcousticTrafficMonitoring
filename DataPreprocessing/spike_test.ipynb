{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93849a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING    /home/timon-l/devel/CITS5551/AcousticTrafficMonitoring/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      " [py.warnings]\n",
      "WARNING:py.warnings:/home/timon-l/devel/CITS5551/AcousticTrafficMonitoring/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from rockpool.devices.xylo.syns61201 import AFESim\n",
    "from rockpool.timeseries import TSContinuous\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c33aad80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_to_features(\n",
    "    input_path: str,\n",
    "    output_dir: str,\n",
    "    label: int,\n",
    "    target_sr: int = 16000,\n",
    "    plot: bool = False\n",
    ") -> str:\n",
    "    fs = 110e3\n",
    "    raster_period = 10e-3\n",
    "    max_spike_per_raster_period = 15\n",
    "    add_noise = True\n",
    "    add_offset = True\n",
    "    add_mismatch = True\n",
    "    seed = None\n",
    "\n",
    "    if not os.path.exists(input_path):\n",
    "        logging.error(f\"File does not exist: {input_path}\")\n",
    "        return ''\n",
    "\n",
    "    y, sr = librosa.load(input_path, sr=target_sr, mono=True)\n",
    "\n",
    "    dt = 1.0 / target_sr\n",
    "    ts = TSContinuous.from_clocked(y, dt=dt, name='Audio input')\n",
    "\n",
    "    afe = AFESim(\n",
    "        fs=fs,\n",
    "        raster_period=raster_period,\n",
    "        max_spike_per_raster_period=max_spike_per_raster_period,\n",
    "        add_noise=add_noise,\n",
    "        add_offset=add_offset,\n",
    "        add_mismatch=add_mismatch,\n",
    "        seed=seed\n",
    "    ).timed()\n",
    "\n",
    "    features, stat, rec = afe(ts, record=True)\n",
    "    raster = features.raster(dt=raster_period, add_events=True)\n",
    "\n",
    "    if plot:\n",
    "        fig, axs = plt.subplots(3, 1, figsize=(16, 12), sharex=False)\n",
    "\n",
    "        time_axis = np.linspace(0, len(y) / sr, num=len(y))\n",
    "        axs[0].plot(time_axis, y, linewidth=0.8)\n",
    "        axs[0].set_title(\"Audio waveform\")\n",
    "        axs[0].set_ylabel(\"Amplitude\")\n",
    "        axs[0].grid(True)\n",
    "\n",
    "        spike_counts = np.sum(raster, axis=1)\n",
    "        time_bins = np.arange(len(spike_counts)) * raster_period\n",
    "        axs[1].plot(time_bins, spike_counts, color='orange', linewidth=0.8)\n",
    "        axs[1].set_title(\"Spike count per raster period\")\n",
    "        axs[1].set_ylabel(\"Spike count\")\n",
    "        axs[1].set_xlabel(\"Time (s)\")\n",
    "        axs[1].grid(True)\n",
    "\n",
    "        axs[2].imshow(raster.T, aspect='auto', origin='lower', extent=[\n",
    "            0, len(spike_counts)*raster_period, 0, raster.shape[1]])\n",
    "        axs[2].set_title(\"Spiking raster\")\n",
    "        axs[2].set_xlabel(\"Time (s)\")\n",
    "        axs[2].set_ylabel(\"Output channel\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    base = os.path.splitext(os.path.basename(input_path))[0]\n",
    "    out_name = f\"{base}.npy\"\n",
    "    out_path = os.path.join(output_dir, out_name)\n",
    "    return out_path, raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0426f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_stretch(y, rate):\n",
    "    return librosa.effects.time_stretch(y, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98ec200b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pitch_shift(y, sr, n_steps):\n",
    "    return librosa.effects.pitch_shift(y, sr=sr, n_steps=n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52086f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse(y):\n",
    "    return y[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d74475f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bandpass_filter(y: np.ndarray) -> np.ndarray:\n",
    "    return librosa.effects.preemphasis(y, coef=0.97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6bff521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_noise(y: np.ndarray, sr: int, noise_duration = 0.5) -> float:\n",
    "    n = int(noise_duration * sr)\n",
    "    noise_rms = np.sqrt(np.mean(y[:n]**2))\n",
    "    return noise_rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef8148d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_audio(y: np.ndarray) -> np.ndarray:\n",
    "    if y.ndim > 1:\n",
    "        y = np.mean(y, axis=1)\n",
    "    peak = np.max(np.abs(y)) + 1e-9\n",
    "    return y / peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2720ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_with_background(y, bg, snr_db=5):\n",
    "    if len(bg) < len(y):\n",
    "        bg = np.tile(bg, int(np.ceil(len(y)/len(bg))))\n",
    "    bg = bg[:len(y)]\n",
    "    rms_y = np.sqrt(np.mean(y**2))\n",
    "    rms_bg = np.sqrt(np.mean(bg**2))\n",
    "    alpha = rms_y / (10**(snr_db/20)) / (rms_bg + 1e-6)\n",
    "    return y + alpha * bg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0030892b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_and_filter(\n",
    "    input_path: str,\n",
    "    output_dir: str,\n",
    "    segment_length: float = 8.0\n",
    ") -> list:\n",
    "\n",
    "    y, sr = librosa.load(input_path, sr=16000, mono=True)\n",
    "    y = normalize_audio(y)\n",
    "\n",
    "    seg_samples = int(segment_length * sr)\n",
    "    total = len(y)\n",
    "    if seg_samples <= 0:\n",
    "        return []\n",
    "\n",
    "    metrics = []  # (start, rms, peak, centroid)\n",
    "    for start in range(0, total - seg_samples + 1, seg_samples):\n",
    "        seg = y[start:start + seg_samples]\n",
    "        rms = np.sqrt(np.mean(seg**2))\n",
    "        peak = np.max(np.abs(seg))\n",
    "        cent = np.mean(librosa.feature.spectral_centroid(y=seg, sr=sr)[0])\n",
    "        metrics.append((start, rms, peak, cent))\n",
    "\n",
    "    if not metrics:\n",
    "        return []\n",
    "\n",
    "    rms_vals = np.array([m[1] for m in metrics], dtype=float)\n",
    "    peak_vals = np.array([m[2] for m in metrics], dtype=float)\n",
    "    cent_vals = np.array([m[3] for m in metrics], dtype=float)\n",
    "    energy_th = float(np.median(rms_vals) * 1.2)\n",
    "    peak_th = float(np.median(peak_vals) * 1.2)\n",
    "    cent_th = float(np.median(cent_vals))\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    base = os.path.splitext(os.path.basename(input_path))[0]\n",
    "    valid = []\n",
    "\n",
    "    for start, rms, peak, cent in metrics:\n",
    "        if rms >= energy_th and peak >= peak_th:\n",
    "            seg = y[start:start + seg_samples]\n",
    "            if cent < cent_th * 0.9:\n",
    "                label = 1\n",
    "            elif cent > cent_th * 1.1:\n",
    "                label = 0\n",
    "            else:\n",
    "                label = 2\n",
    "            out_name = f\"{base}_s{start}_lbl{label}.flac\"\n",
    "            out_path = os.path.join(output_dir, out_name)\n",
    "            sf.write(out_path, seg, sr)\n",
    "            logging.info(f\"Saved segment: {out_path}\")\n",
    "            valid.append((out_path, label, start))\n",
    "    return valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "248b0daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_cv(audio, sr, noise_path=None):\n",
    "    augmented = []\n",
    "\n",
    "    reversed_audio = audio[::-1]\n",
    "    augmented.append(reversed_audio)\n",
    "\n",
    "    for rate in [0.9, 1.1]:\n",
    "        y_stretch = librosa.effects.time_stretch(audio, rate=rate)\n",
    "        augmented.append(y_stretch)\n",
    "\n",
    "    if noise_path:\n",
    "        noise, _ = librosa.load(noise_path, sr=sr)\n",
    "        min_len = min(len(audio), len(noise))\n",
    "        mixed = audio[:min_len] + 0.2 * noise[:min_len]\n",
    "        augmented.append(mixed)\n",
    "\n",
    "    return augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ddbca28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_npy_file(npy_path: str, max_channels: int = 16) -> bool:\n",
    "    try:\n",
    "        data = np.load(npy_path)\n",
    "\n",
    "        if not isinstance(data, np.ndarray):\n",
    "            logging.error(f\"{npy_path} is not a valid NumPy array.\")\n",
    "            return False\n",
    "\n",
    "        if data.ndim != 2:\n",
    "            logging.error(f\"{npy_path} has {data.ndim} dims, expected 2D.\")\n",
    "            return False\n",
    "\n",
    "        time_steps, channels = data.shape\n",
    "        if channels > max_channels:\n",
    "            logging.error(f\"{npy_path} has {channels} channels, exceeds max {max_channels}.\")\n",
    "            return False\n",
    "\n",
    "        if not np.issubdtype(data.dtype, np.integer):\n",
    "            logging.error(f\"{npy_path} data type is {data.dtype}, expected integer type.\")\n",
    "            return False\n",
    "\n",
    "        if np.isnan(data).any():\n",
    "            logging.error(f\"{npy_path} contains NaN values.\")\n",
    "            return False\n",
    "\n",
    "        if (data < 0).any():\n",
    "            logging.warning(f\"{npy_path} contains negative values.\")\n",
    "\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error validating {npy_path}: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f534a040",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def get_class_name_and_split(filepath):\n",
    "    parts = Path(filepath).parts\n",
    "    for i, part in enumerate(parts):\n",
    "        if part in ['car', 'cv', 'background', 'cv_aug']:\n",
    "            raw_class = part\n",
    "            break\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown class in path: {filepath}\")\n",
    "\n",
    "    class_map = {\n",
    "        'car': 'Car',\n",
    "        'cv': 'CommercialVehicle',\n",
    "        'background': 'Background',\n",
    "        'cv_aug': 'CommercialVehicle'\n",
    "    }\n",
    "\n",
    "    class_name = class_map[raw_class]\n",
    "\n",
    "    split = 'Test' if 'val' in filepath.lower() else 'Train'\n",
    "    return class_name, split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43f540a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_clip(args):\n",
    "    input_path, split, data_dir = args\n",
    "    out_path = None\n",
    "\n",
    "    try:\n",
    "        cls = Path(input_path).parent.name.lower()\n",
    "        if cls == 'car':\n",
    "            label = 0; class_name = 'Car'\n",
    "        elif cls in ('cv', 'cv_aug'):\n",
    "            label = 1; class_name = 'CommercialVehicle'\n",
    "        elif cls == 'background':\n",
    "            label = 2; class_name = 'Background'\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown class '{cls}'\")\n",
    "\n",
    "        output_dir = os.path.join(data_dir, split, class_name)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        out_path, raster = audio_to_features(\n",
    "            input_path=input_path,\n",
    "            output_dir=output_dir,\n",
    "            label=label,\n",
    "            plot=False\n",
    "        )\n",
    "        if not out_path:\n",
    "            raise RuntimeError(\"audio_to_features returned no path\")\n",
    "\n",
    "        np.save(out_path, raster)\n",
    "        if not validate_npy_file(out_path):\n",
    "            os.remove(out_path)\n",
    "            logging.warning(f\"Invalid .npy removed: {out_path}\")\n",
    "            return False\n",
    "\n",
    "        logging.info(f\"Saved & validated: {out_path}\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"[FAIL] {input_path}: {e}\")\n",
    "        if out_path and os.path.exists(out_path):\n",
    "            os.remove(out_path)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3524eb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def stratify_paths(paths, frac=0.15, seed=42):\n",
    "    random.seed(seed)\n",
    "    random.shuffle(paths)\n",
    "    n = len(paths)\n",
    "    n_val = int(frac * n)\n",
    "    n_test = n_val\n",
    "    n_train = n - n_val - n_test\n",
    "    return paths[:n_train], paths[n_train:n_train+n_val], paths[n_train+n_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5412ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts before split: 100000 car | 100000 cv | 100000 background\n",
      "After stratification:\n",
      "  train sizes: car 70000 cv 70000 bg 70000\n",
      "  val   sizes: car 15000 cv 15000 bg 15000\n",
      "  test  sizes: car 15000 cv 15000 bg 15000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-12:\n",
      "Process ForkPoolWorker-8:\n",
      "Process ForkPoolWorker-6:\n",
      "Process ForkPoolWorker-10:\n",
      "Process ForkPoolWorker-16:\n",
      "Process ForkPoolWorker-7:\n",
      "Process ForkPoolWorker-13:\n",
      "Process ForkPoolWorker-14:\n",
      "Process ForkPoolWorker-9:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-11:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-15:\n",
      "  File \"/home/timon-l/.pyenv/versions/3.11.7/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/timon-l/.pyenv/versions/3.11.7/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/timon-l/.pyenv/versions/3.11.7/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/timon-l/.pyenv/versions/3.11.7/lib/python3.11/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "                    ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/timon-l/.pyenv/versions/3.11.7/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/timon-l/.pyenv/versions/3.11.7/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/timon-l/.pyenv/versions/3.11.7/lib/python3.11/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/timon-l/.pyenv/versions/3.11.7/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/timon-l/.pyenv/versions/3.11.7/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 79\u001b[39m\n\u001b[32m     76\u001b[39m         tasks.append((p, split, data_dir))\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Pool(cpu_count()) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     results = \u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_clip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m succ = \u001b[38;5;28msum\u001b[39m(results)\n\u001b[32m     82\u001b[39m tot = \u001b[38;5;28mlen\u001b[39m(results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/multiprocessing/pool.py:367\u001b[39m, in \u001b[36mPool.map\u001b[39m\u001b[34m(self, func, iterable, chunksize)\u001b[39m\n\u001b[32m    362\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    363\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m'''\u001b[39;00m\n\u001b[32m    364\u001b[39m \u001b[33;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[32m    365\u001b[39m \u001b[33;03m    in a list that is returned.\u001b[39;00m\n\u001b[32m    366\u001b[39m \u001b[33;03m    '''\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m367\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/multiprocessing/pool.py:768\u001b[39m, in \u001b[36mApplyResult.get\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    767\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m768\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    769\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ready():\n\u001b[32m    770\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/multiprocessing/pool.py:765\u001b[39m, in \u001b[36mApplyResult.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    764\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m765\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_event\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/threading.py:629\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    627\u001b[39m signaled = \u001b[38;5;28mself\u001b[39m._flag\n\u001b[32m    628\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[32m--> \u001b[39m\u001b[32m629\u001b[39m     signaled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    630\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.7/lib/python3.11/threading.py:327\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    329\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import random\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    logging.basicConfig(\n",
    "        filename='spike_test.log',\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s %(levelname)s %(message)s'\n",
    "    )\n",
    "    base_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "    seg_dir = os.path.join(base_dir, 'vehicle_segments')\n",
    "    input_csv = os.path.join(seg_dir, 'vehicle_clips.csv')\n",
    "    background_dir = os.path.join(seg_dir, 'background')\n",
    "\n",
    "    data_dir = os.path.join(base_dir, 'npy')\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "    if not os.path.exists(input_csv):\n",
    "        logging.error(f\"input CSV not found at: {input_csv}\")\n",
    "        exit(1)\n",
    "\n",
    "    df = pd.read_csv(input_csv)\n",
    "    df_car = df[\n",
    "        (df['label'] == 0) &\n",
    "        (~df['filepath'].str.contains('cv_aug')) &\n",
    "        (~df['filepath'].str.contains('cv'))\n",
    "    ]\n",
    "\n",
    "    df_car = df_car.sample(n=min(1000, len(df_car)), random_state=42)\n",
    "\n",
    "    df_cv = df[\n",
    "        (df['label'] == 1)\n",
    "    ].sample(\n",
    "        n=min(1000, len(df[df['label'] == 1])),\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    bg_files = glob(os.path.join(background_dir, '*.wav'))\n",
    "    bg_files = random.sample(bg_files, min(1000, len(bg_files)))\n",
    "\n",
    "    car_paths = df_car['filepath'].tolist()\n",
    "    cv_paths = df_cv['filepath'].tolist()\n",
    "    bg_paths = bg_files\n",
    "\n",
    "    print(\"Counts before split:\",\n",
    "          len(car_paths), \"car |\",\n",
    "          len(cv_paths),  \"cv |\",\n",
    "          len(bg_paths),  \"background\")\n",
    "\n",
    "    car_train, car_val, car_test = stratify_paths(car_paths)\n",
    "    cv_train,  cv_val,  cv_test = stratify_paths(cv_paths)\n",
    "    bg_train,  bg_val,  bg_test = stratify_paths(bg_paths)\n",
    "\n",
    "    print(\"After stratification:\")\n",
    "    print(\"  train sizes: car\", len(car_train),\n",
    "          \"cv\", len(cv_train), \"bg\", len(bg_train))\n",
    "    print(\"  val   sizes: car\", len(car_val),\n",
    "          \"cv\", len(cv_val), \"bg\", len(bg_val))\n",
    "    print(\"  test  sizes: car\", len(car_test),\n",
    "          \"cv\", len(cv_test), \"bg\", len(bg_test))\n",
    "\n",
    "    tasks = []\n",
    "    for split, paths in [\n",
    "        ('Train', car_train),\n",
    "        ('Val',   car_val),\n",
    "        ('Test',  car_test),\n",
    "        ('Train', cv_train),\n",
    "        ('Val',   cv_val),\n",
    "        ('Test',  cv_test),\n",
    "        ('Train', bg_train),\n",
    "        ('Val',   bg_val),\n",
    "        ('Test',  bg_test),\n",
    "    ]:\n",
    "        for p in paths:\n",
    "            tasks.append((p, split, data_dir))\n",
    "\n",
    "    with Pool(cpu_count()) as pool:\n",
    "        results = pool.map(process_clip, tasks, chunksize=10)\n",
    "\n",
    "    succ = sum(results)\n",
    "    tot = len(results)\n",
    "    print(f\"Done: {succ}/{tot} succeeded across Train/Val/Test.\")\n",
    "    logging.info(f\"Finished splits â€“ success {succ}/{tot}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
