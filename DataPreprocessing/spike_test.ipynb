{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93849a90",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'rockpool'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrockpool\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdevices\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mxylo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msyns61201\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AFESim\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrockpool\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtimeseries\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TSContinuous\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlibrosa\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'rockpool'"
     ]
    }
   ],
   "source": [
    "!pip install rockpool\n",
    "\n",
    "from rockpool.devices.xylo.syns61201 import AFESim\n",
    "from rockpool.timeseries import TSContinuous\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33aad80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_to_features(\n",
    "    input_path: str,\n",
    "    output_dir: str,\n",
    "    label: int,\n",
    "    target_sr: int = 16000,\n",
    "    plot: bool = False\n",
    ") -> str:\n",
    "    fs = 110e3\n",
    "    raster_period = 10e-3\n",
    "    max_spike_per_raster_period = 15\n",
    "    add_noise = True\n",
    "    add_offset = True\n",
    "    add_mismatch = True\n",
    "    seed = None\n",
    "\n",
    "    if not os.path.exists(input_path):\n",
    "        logging.error(f\"File does not exist: {input_path}\")\n",
    "        return ''\n",
    "\n",
    "    y, sr = librosa.load(input_path, sr=target_sr, mono=True)\n",
    "\n",
    "    dt = 1.0 / target_sr\n",
    "    ts = TSContinuous.from_clocked(y, dt=dt, name='Audio input')\n",
    "\n",
    "    afe = AFESim(\n",
    "        fs=fs,\n",
    "        raster_period=raster_period,\n",
    "        max_spike_per_raster_period=max_spike_per_raster_period,\n",
    "        add_noise=add_noise,\n",
    "        add_offset=add_offset,\n",
    "        add_mismatch=add_mismatch,\n",
    "        seed=seed\n",
    "    ).timed()\n",
    "\n",
    "    features, stat, rec = afe(ts, record=True)\n",
    "    raster = features.raster(dt=raster_period, add_events=True)\n",
    "\n",
    "    if plot:\n",
    "        fig, axs = plt.subplots(3, 1, figsize=(16, 12), sharex=False)\n",
    "\n",
    "        time_axis = np.linspace(0, len(y) / sr, num=len(y))\n",
    "        axs[0].plot(time_axis, y, linewidth=0.8)\n",
    "        axs[0].set_title(\"Audio waveform\")\n",
    "        axs[0].set_ylabel(\"Amplitude\")\n",
    "        axs[0].grid(True)\n",
    "\n",
    "        spike_counts = np.sum(raster, axis=1)\n",
    "        time_bins = np.arange(len(spike_counts)) * raster_period\n",
    "        axs[1].plot(time_bins, spike_counts, color='orange', linewidth=0.8)\n",
    "        axs[1].set_title(\"Spike count per raster period\")\n",
    "        axs[1].set_ylabel(\"Spike count\")\n",
    "        axs[1].set_xlabel(\"Time (s)\")\n",
    "        axs[1].grid(True)\n",
    "\n",
    "        axs[2].imshow(raster.T, aspect='auto', origin='lower', extent=[\n",
    "            0, len(spike_counts)*raster_period, 0, raster.shape[1]])\n",
    "        axs[2].set_title(\"Spiking raster\")\n",
    "        axs[2].set_xlabel(\"Time (s)\")\n",
    "        axs[2].set_ylabel(\"Output channel\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    base = os.path.splitext(os.path.basename(input_path))[0]\n",
    "    out_name = f\"{base}.npy\"\n",
    "    out_path = os.path.join(output_dir, out_name)\n",
    "    return out_path, raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0426f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_stretch(y, rate):\n",
    "    return librosa.effects.time_stretch(y, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ec200b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pitch_shift(y, sr, n_steps):\n",
    "    return librosa.effects.pitch_shift(y, sr=sr, n_steps=n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52086f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse(y):\n",
    "    return y[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d74475f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bandpass_filter(y: np.ndarray) -> np.ndarray:\n",
    "    return librosa.effects.preemphasis(y, coef=0.97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bff521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_noise(y: np.ndarray, sr: int, noise_duration = 0.5) -> float:\n",
    "    n = int(noise_duration * sr)\n",
    "    noise_rms = np.sqrt(np.mean(y[:n]**2))\n",
    "    return noise_rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8148d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_audio(y: np.ndarray) -> np.ndarray:\n",
    "    if y.ndim > 1:\n",
    "        y = np.mean(y, axis=1)\n",
    "    peak = np.max(np.abs(y)) + 1e-9\n",
    "    return y / peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2720ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_with_background(y, bg, snr_db=5):\n",
    "    if len(bg) < len(y):\n",
    "        bg = np.tile(bg, int(np.ceil(len(y)/len(bg))))\n",
    "    bg = bg[:len(y)]\n",
    "    rms_y = np.sqrt(np.mean(y**2))\n",
    "    rms_bg = np.sqrt(np.mean(bg**2))\n",
    "    alpha = rms_y / (10**(snr_db/20)) / (rms_bg + 1e-6)\n",
    "    return y + alpha * bg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0030892b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_and_filter(\n",
    "    input_path: str,\n",
    "    output_dir: str,\n",
    "    segment_length: float = 8.0\n",
    ") -> list:\n",
    "\n",
    "    y, sr = librosa.load(input_path, sr=16000, mono=True)\n",
    "    y = normalize_audio(y)\n",
    "\n",
    "    seg_samples = int(segment_length * sr)\n",
    "    total = len(y)\n",
    "    if seg_samples <= 0:\n",
    "        return []\n",
    "\n",
    "    metrics = []  # (start, rms, peak, centroid)\n",
    "    for start in range(0, total - seg_samples + 1, seg_samples):\n",
    "        seg = y[start:start + seg_samples]\n",
    "        rms = np.sqrt(np.mean(seg**2))\n",
    "        peak = np.max(np.abs(seg))\n",
    "        cent = np.mean(librosa.feature.spectral_centroid(y=seg, sr=sr)[0])\n",
    "        metrics.append((start, rms, peak, cent))\n",
    "\n",
    "    if not metrics:\n",
    "        return []\n",
    "\n",
    "    rms_vals = np.array([m[1] for m in metrics], dtype=float)\n",
    "    peak_vals = np.array([m[2] for m in metrics], dtype=float)\n",
    "    cent_vals = np.array([m[3] for m in metrics], dtype=float)\n",
    "    energy_th = float(np.median(rms_vals) * 1.2)\n",
    "    peak_th = float(np.median(peak_vals) * 1.2)\n",
    "    cent_th = float(np.median(cent_vals))\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    base = os.path.splitext(os.path.basename(input_path))[0]\n",
    "    valid = []\n",
    "\n",
    "    for start, rms, peak, cent in metrics:\n",
    "        if rms >= energy_th and peak >= peak_th:\n",
    "            seg = y[start:start + seg_samples]\n",
    "            if cent < cent_th * 0.9:\n",
    "                label = 1\n",
    "            elif cent > cent_th * 1.1:\n",
    "                label = 0\n",
    "            else:\n",
    "                label = 2\n",
    "            out_name = f\"{base}_s{start}_lbl{label}.flac\"\n",
    "            out_path = os.path.join(output_dir, out_name)\n",
    "            sf.write(out_path, seg, sr)\n",
    "            logging.info(f\"Saved segment: {out_path}\")\n",
    "            valid.append((out_path, label, start))\n",
    "    return valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248b0daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_cv(audio, sr, noise_path=None):\n",
    "    augmented = []\n",
    "\n",
    "    reversed_audio = audio[::-1]\n",
    "    augmented.append(reversed_audio)\n",
    "\n",
    "    for rate in [0.9, 1.1]:\n",
    "        y_stretch = librosa.effects.time_stretch(audio, rate=rate)\n",
    "        augmented.append(y_stretch)\n",
    "\n",
    "    if noise_path:\n",
    "        noise, _ = librosa.load(noise_path, sr=sr)\n",
    "        min_len = min(len(audio), len(noise))\n",
    "        mixed = audio[:min_len] + 0.2 * noise[:min_len]\n",
    "        augmented.append(mixed)\n",
    "\n",
    "    return augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddbca28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_npy_file(npy_path: str, max_channels: int = 16) -> bool:\n",
    "    try:\n",
    "        data = np.load(npy_path)\n",
    "\n",
    "        if not isinstance(data, np.ndarray):\n",
    "            logging.error(f\"{npy_path} is not a valid NumPy array.\")\n",
    "            return False\n",
    "\n",
    "        if data.ndim != 2:\n",
    "            logging.error(f\"{npy_path} has {data.ndim} dims, expected 2D.\")\n",
    "            return False\n",
    "\n",
    "        time_steps, channels = data.shape\n",
    "        if channels > max_channels:\n",
    "            logging.error(f\"{npy_path} has {channels} channels, exceeds max {max_channels}.\")\n",
    "            return False\n",
    "\n",
    "        if not np.issubdtype(data.dtype, np.integer):\n",
    "            logging.error(f\"{npy_path} data type is {data.dtype}, expected integer type.\")\n",
    "            return False\n",
    "\n",
    "        if np.isnan(data).any():\n",
    "            logging.error(f\"{npy_path} contains NaN values.\")\n",
    "            return False\n",
    "\n",
    "        if (data < 0).any():\n",
    "            logging.warning(f\"{npy_path} contains negative values.\")\n",
    "\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error validating {npy_path}: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f534a040",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def get_class_name_and_split(filepath):\n",
    "    parts = Path(filepath).parts\n",
    "    for i, part in enumerate(parts):\n",
    "        if part in ['car', 'cv', 'background', 'cv_aug']:\n",
    "            raw_class = part\n",
    "            break\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown class in path: {filepath}\")\n",
    "\n",
    "    class_map = {\n",
    "        'car': 'Car',\n",
    "        'cv': 'CommercialVehicle',\n",
    "        'background': 'Background',\n",
    "        'cv_aug': 'CommercialVehicle'\n",
    "    }\n",
    "\n",
    "    class_name = class_map[raw_class]\n",
    "\n",
    "    split = 'Test' if 'val' in filepath.lower() else 'Train'\n",
    "    return class_name, split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f540a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_clip(args):\n",
    "    input_path, split, data_dir = args\n",
    "    out_path = None\n",
    "\n",
    "    try:\n",
    "        cls = Path(input_path).parent.name.lower()\n",
    "        if cls == 'car':\n",
    "            label = 0; class_name = 'Car'\n",
    "        elif cls in ('cv', 'cv_aug'):\n",
    "            label = 1; class_name = 'CommercialVehicle'\n",
    "        elif cls == 'background':\n",
    "            label = 2; class_name = 'Background'\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown class '{cls}'\")\n",
    "\n",
    "        output_dir = os.path.join(data_dir, split, class_name)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        out_path, raster = audio_to_features(\n",
    "            input_path=input_path,\n",
    "            output_dir=output_dir,\n",
    "            label=label,\n",
    "            plot=False\n",
    "        )\n",
    "        if not out_path:\n",
    "            raise RuntimeError(\"audio_to_features returned no path\")\n",
    "\n",
    "        np.save(out_path, raster)\n",
    "        if not validate_npy_file(out_path):\n",
    "            os.remove(out_path)\n",
    "            logging.warning(f\"Invalid .npy removed: {out_path}\")\n",
    "            return False\n",
    "\n",
    "        logging.info(f\"Saved & validated: {out_path}\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"[FAIL] {input_path}: {e}\")\n",
    "        if out_path and os.path.exists(out_path):\n",
    "            os.remove(out_path)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3524eb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def stratify_paths(paths, frac=0.15, seed=42):\n",
    "    random.seed(seed)\n",
    "    random.shuffle(paths)\n",
    "    n = len(paths)\n",
    "    n_val = int(frac * n)\n",
    "    n_test = n_val\n",
    "    n_train = n - n_val - n_test\n",
    "    return paths[:n_train], paths[n_train:n_train+n_val], paths[n_train+n_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5412ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logging' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m'\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m      7\u001b[39m     sample_size = \u001b[32m100000\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     \u001b[43mlogging\u001b[49m.basicConfig(\n\u001b[32m      9\u001b[39m         filename=\u001b[33m'\u001b[39m\u001b[33mspike_test.log\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     10\u001b[39m         level=logging.INFO,\n\u001b[32m     11\u001b[39m         \u001b[38;5;28mformat\u001b[39m=\u001b[33m'\u001b[39m\u001b[38;5;132;01m%(asctime)s\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%(levelname)s\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%(message)s\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m     12\u001b[39m     )\n\u001b[32m     13\u001b[39m     base_dir = os.path.dirname(os.path.abspath(\u001b[33m'\u001b[39m\u001b[33m__file__\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m     14\u001b[39m     seg_dir = os.path.join(base_dir, \u001b[33m'\u001b[39m\u001b[33mnew_vehicle_segments\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'logging' is not defined"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import random\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import tqdm\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    sample_size = 100000\n",
    "    logging.basicConfig(\n",
    "        filename='spike_test.log',\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s %(levelname)s %(message)s'\n",
    "    )\n",
    "    base_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "    seg_dir = os.path.join(base_dir, 'new_vehicle_segments')\n",
    "    input_csv = os.path.join(seg_dir, 'vehicle_clips.csv')\n",
    "    background_dir = os.path.join(seg_dir, 'background')\n",
    "\n",
    "    data_dir = os.path.join(base_dir, 'new_npy')\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "    if not os.path.exists(input_csv):\n",
    "        logging.error(f\"input CSV not found at: {input_csv}\")\n",
    "        exit(1)\n",
    "\n",
    "    df = pd.read_csv(input_csv)\n",
    "    df_car = df[\n",
    "        (df['label'] == 0) &\n",
    "        (~df['filepath'].str.contains('cv_aug')) &\n",
    "        (~df['filepath'].str.contains('cv'))\n",
    "    ]\n",
    "\n",
    "    df_car = df_car.sample(n=min(sample_size , len(df_car)), random_state=42)\n",
    "\n",
    "    df_cv = df[\n",
    "        (df['label'] == 1)\n",
    "    ].sample(\n",
    "        n=min(sample_size , len(df[df['label'] == 1])),\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    bg_files = glob(os.path.join(background_dir, '*.wav'))\n",
    "    bg_files = random.sample(bg_files, min(sample_size , len(bg_files)))\n",
    "\n",
    "    car_paths = df_car['filepath'].tolist()\n",
    "    cv_paths = df_cv['filepath'].tolist()\n",
    "    bg_paths = bg_files\n",
    "\n",
    "    print(\"Counts before split:\",\n",
    "          len(car_paths), \"car |\",\n",
    "          len(cv_paths),  \"cv |\",\n",
    "          len(bg_paths),  \"background\")\n",
    "\n",
    "    car_train, car_val, car_test = stratify_paths(car_paths)\n",
    "    cv_train,  cv_val,  cv_test = stratify_paths(cv_paths)\n",
    "    bg_train,  bg_val,  bg_test = stratify_paths(bg_paths)\n",
    "\n",
    "    print(\"After stratification:\")\n",
    "    print(\"  train sizes: car\", len(car_train),\n",
    "          \"cv\", len(cv_train), \"bg\", len(bg_train))\n",
    "    print(\"  val   sizes: car\", len(car_val),\n",
    "          \"cv\", len(cv_val), \"bg\", len(bg_val))\n",
    "    print(\"  test  sizes: car\", len(car_test),\n",
    "          \"cv\", len(cv_test), \"bg\", len(bg_test))\n",
    "\n",
    "    tasks = []\n",
    "    for split, paths in [\n",
    "        ('Train', car_train),\n",
    "        ('Val',   car_val),\n",
    "        ('Test',  car_test),\n",
    "        ('Train', cv_train),\n",
    "        ('Val',   cv_val),\n",
    "        ('Test',  cv_test),\n",
    "        ('Train', bg_train),\n",
    "        ('Val',   bg_val),\n",
    "        ('Test',  bg_test),\n",
    "    ]:\n",
    "        for p in paths:\n",
    "            tasks.append((p, split, data_dir))\n",
    "\n",
    "    with tqdm(total=len(car_paths)+len(cv_paths)+len(bg_paths)) as pbar:\n",
    "        with Pool(cpu_count()) as pool:\n",
    "            results = pool.map(process_clip, tasks, chunksize=10)\n",
    "            pbar.update(1)\n",
    "\n",
    "    succ = sum(results)\n",
    "    tot = len(results)\n",
    "    print(f\"Done: {succ}/{tot} succeeded across Train/Val/Test.\")\n",
    "    logging.info(f\"Finished splits – success {succ}/{tot}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8a1e06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
