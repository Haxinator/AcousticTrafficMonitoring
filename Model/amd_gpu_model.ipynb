{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603aa51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è Using device: cpu\n",
      "torch.Size([2113, 100, 16])\n",
      "torch.Size([2113])\n",
      "torch.Size([374, 100, 16])\n",
      "torch.Size([374])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:36<20:17:44, 36.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ New best model saved!\n",
      "Epoch 0: Loss 8.4687, Training Accuracy 38.45%, Val Accuracy 58.82%\n"
     ]
    }
   ],
   "source": [
    "# NOTES\n",
    "'''\n",
    "In 100 epochs:\n",
    " - Using vmem as output increases accuracy by about 8 percent.\n",
    " - Using MSE increases accuracy by about 2 percent.\n",
    "'''\n",
    "\n",
    "# Use SynNet to start. We Will need to develop our own architecture later.\n",
    "# Still able to make some small adjustments to the network though.\n",
    "from rockpool.nn.networks import SynNet\n",
    "from rockpool.nn.modules import LIFTorch\n",
    "# - Import torch training utilities\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.nn import MSELoss\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# data transformations and caching.\n",
    "import tonic\n",
    "import tonic.transforms as T\n",
    "\n",
    "# for paths\n",
    "import os\n",
    "import logging\n",
    "\n",
    "# progress bar\n",
    "from tqdm import trange\n",
    "\n",
    "# saving and loading json for stats\n",
    "import json\n",
    "\n",
    "# visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# need about 37000 epochs to get good accuracy\n",
    "n_epochs = 100\n",
    "n_batches = 8\n",
    "n_time = 100\n",
    "n_labels = 3\n",
    "net_channels = 16\n",
    "\n",
    "# -------------------------- MODIFICATION FOR AMD GPU -------------------------#\n",
    "# - Use ROCm for AMD GPUs if available, otherwise fall back to CPU\n",
    "if torch.cuda.is_available():\n",
    "    dev = \"cuda:0\"  # For NVIDIA GPUs\n",
    "elif torch.backends.mps.is_available():\n",
    "    dev = \"mps\"  # For Apple Silicon\n",
    "elif torch.version.hip is not None and torch.cuda.is_available():\n",
    "    dev = \"cuda:0\"  # Fallback for ROCm on some systems\n",
    "else:\n",
    "    dev = \"cpu\"\n",
    "\n",
    "device = torch.device(dev)\n",
    "print(f\"‚öôÔ∏è Using device: {device}\")\n",
    "# ----------------------------- END MODIFICATION ------------------------------#\n",
    "\n",
    "# ----------------------------- LOAD DATA --------------------------#\n",
    "\n",
    "dataloader_kwargs = dict(\n",
    "    batch_size=n_batches,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    pin_memory=True,\n",
    "    collate_fn=tonic.collation.PadTensors(batch_first=True),\n",
    "    num_workers=8,\n",
    ")\n",
    "\n",
    "dataloader_val_kwargs = dict(\n",
    "    batch_size=n_batches,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    "    pin_memory=True,\n",
    "    collate_fn=tonic.collation.PadTensors(batch_first=True),\n",
    "    num_workers=8,\n",
    ")\n",
    "\n",
    "dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "base_dir = os.path.join(dir, \"../DataPreprocessing\")\n",
    "mingDataPath = os.path.join(dir, \"../DataPreprocessing\")\n",
    "\n",
    "# CUDA results in x5 speed increase.\n",
    "# ming data results in x6 speed increase.\n",
    "# data caching significantly slower (6x slower) than loading ming data.\n",
    "X_train = torch.from_numpy(\n",
    "    np.load(os.path.join(mingDataPath, \"X_train.npy\"))).float()\n",
    "y_train = torch.from_numpy(\n",
    "    np.load(os.path.join(mingDataPath, \"y_train.npy\"))).long()\n",
    "X_val = torch.from_numpy(\n",
    "    np.load(os.path.join(mingDataPath, \"X_val.npy\"))).float()\n",
    "y_val = torch.from_numpy(\n",
    "    np.load(os.path.join(mingDataPath, \"y_val.npy\"))).long()\n",
    "X_test = torch.from_numpy(\n",
    "    np.load(os.path.join(mingDataPath, \"X_test.npy\"))).float()\n",
    "y_test = torch.from_numpy(\n",
    "    np.load(os.path.join(mingDataPath, \"y_test.npy\"))).long()\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "\n",
    "train_ds = TensorDataset(X_train, y_train)\n",
    "val_ds = TensorDataset(X_val, y_val)\n",
    "test_ds = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=n_batches, shuffle=True,\n",
    "                      drop_last=True, pin_memory=True, num_workers=6)\n",
    "val_dl = DataLoader(val_ds, batch_size=n_batches, shuffle=False,\n",
    "                    drop_last=False, pin_memory=True, num_workers=6)\n",
    "test_dl = DataLoader(test_ds, batch_size=n_batches, shuffle=False,\n",
    "                     drop_last=False, pin_memory=True, num_workers=6)\n",
    "\n",
    "# A manual seed ensures repeatability\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Create an empty dictionary for the neuron model arguments\n",
    "default_neuron_kwargs = {}\n",
    "\n",
    "# - Build a simple SynNet with three hidden layers\n",
    "# Need to experiment with number of layers, neurons and time constants.\n",
    "net = SynNet(\n",
    "    neuron_model=LIFTorch,\n",
    "    # Use the membrane potential as the output of the network.\n",
    "    output=\"vmem\",\n",
    "    # probability of dropout (good to prevent overfitting).\n",
    "    p_dropout=0.1,\n",
    "\n",
    "    # time constants and threshold are not trainable by default.\n",
    "    # NOTE if not using SynNet then they will be by default.\n",
    "\n",
    "    # Number of input channels (always 16)\n",
    "    n_channels=net_channels,\n",
    "    # Number of output classes (car, commercial, background noise).\n",
    "    n_classes=n_labels,\n",
    "    # Number of neurons in each hidden layer (taken from tutorial)\n",
    "    size_hidden_layers=[24, 24, 24],\n",
    "    # Number of time constants in each hidden layer (taken from tutorial)\n",
    "    time_constants_per_layer=[3, 6, 9],\n",
    "    neuron_kwargs=default_neuron_kwargs\n",
    ").to(device)\n",
    "\n",
    "# compile model to make it FAST (doesn't work =( )\n",
    "# net.compile()\n",
    "\n",
    "# print(net)\n",
    "# show trainable parameters (time constants should be empty dict otherwise they will be trained)\n",
    "# print(net.parameters)\n",
    "\n",
    "# pass parameters to optimise and the learning rate (lr) respectively to adam.\n",
    "# must be done after model is moved to GPU (otherwise learning won't occur)\n",
    "optimiser = Adam(net.parameters().astorch(), lr=1e-3)\n",
    "\n",
    "# Dylan recommends using MSE for loss\n",
    "# results in slightly higher accuracy compared to other functions\n",
    "loss_function = MSELoss()\n",
    "# loss_function = CrossEntropyLoss()\n",
    "\n",
    "# ==== 4. MSE defining ====\n",
    "\n",
    "\n",
    "def float_target_mse_loss(outputs, labels, num_classes, pos_val=5.0, neg_val=-1.0):\n",
    "    device = outputs.device\n",
    "    B = labels.shape[0]\n",
    "    target = torch.full((B, num_classes), neg_val, device=device)\n",
    "    target[torch.arange(B, device=device), labels] = pos_val\n",
    "    return F.mse_loss(outputs, target)\n",
    "\n",
    "\n",
    "# no constraints used\n",
    "# no regularisations used\n",
    "\n",
    "# where the model and statistics will be saved\n",
    "best_val_acc = -1\n",
    "correct = 0\n",
    "total = 0\n",
    "total_loss = 0\n",
    "total_epochs = -1\n",
    "best_bot = {}\n",
    "train_acc_list = []\n",
    "train_loss_list = []\n",
    "val_acc_list = []\n",
    "skip_window = 30\n",
    "\n",
    "# initialise stat list to empty (for now)\n",
    "stats = {\"train_acc_list\": train_acc_list, \"train_loss_list\": train_loss_list, \"val_acc_list\": val_acc_list, \"correct\": correct,\n",
    "         \"total\": total, \"total_loss\": total_loss, \"best_val_acc\": best_val_acc, \"total_epochs\": total_epochs, \"test_acc\": 0}\n",
    "best_stat = {\"train_acc_list\": train_acc_list, \"train_loss_list\": train_loss_list, \"val_acc_list\": val_acc_list, \"correct\": correct,\n",
    "             \"total\": total, \"total_loss\": total_loss, \"best_val_acc\": best_val_acc, \"total_epochs\": total_epochs, \"test_acc\": 0}\n",
    "# in function so we can compile training to make it sonic speed.\n",
    "# @torch.compile (doesn't work =( )\n",
    "\n",
    "\n",
    "def train(net, train_dl, val_dl, test_dl):\n",
    "    global train_acc_list, train_loss_list, val_acc_list, best_bot, best_val_acc, optimiser, skip_window, device\n",
    "\n",
    "    # Training loop\n",
    "    # trange gives cool progress bar\n",
    "    for _ in trange(n_epochs):\n",
    "        stats[\"total_epochs\"] += 1\n",
    "        net.train()\n",
    "        loss = 0.0\n",
    "\n",
    "        # batching done by torch/tonic dataloader\n",
    "        for events, labels in train_dl:\n",
    "            events, labels = events.to(device), labels.to(device)\n",
    "            # prevent exploding gradients by reseting gradients every loop\n",
    "            optimiser.zero_grad()\n",
    "\n",
    "            out, _, _ = net(events)\n",
    "            output = out[:, skip_window:, :].mean(dim=1)\n",
    "            loss = float_target_mse_loss(output, labels, num_classes=n_labels)\n",
    "\n",
    "            loss.backward()\n",
    "            # step must be done after calling backward.\n",
    "            optimiser.step()\n",
    "\n",
    "            predicted = torch.argmax(output, 1).to(device)\n",
    "\n",
    "            # to get number of datafiles and number of correct guesses\n",
    "            stats[\"total\"] += labels.size(0)\n",
    "            stats[\"correct\"] += (predicted == labels).sum().item()\n",
    "            stats[\"total_loss\"] += loss.item() * events.size(0)\n",
    "\n",
    "        # VAL LOOP\n",
    "        accuracy_val = -1\n",
    "\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "\n",
    "            for events, labels in val_dl:\n",
    "                events, labels = events.to(device), labels.to(device)\n",
    "                out, _, _ = net(events)\n",
    "\n",
    "                output = out[:, skip_window:, :].mean(\n",
    "                    dim=1)  # using skip and mean value vmem\n",
    "\n",
    "                predicted = torch.argmax(output, 1).to(device)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            accuracy_val = (val_correct/val_total)*100\n",
    "\n",
    "        accuracy = 100 * stats[\"correct\"] / stats[\"total\"]\n",
    "        avg_loss = stats[\"total_loss\"] / stats[\"total\"]\n",
    "\n",
    "        stats[\"train_acc_list\"].append(accuracy)\n",
    "        stats[\"val_acc_list\"].append(accuracy_val)\n",
    "        stats[\"train_loss_list\"].append(avg_loss)\n",
    "\n",
    "        if (accuracy_val > stats[\"best_val_acc\"]):\n",
    "            stats[\"best_val_acc\"] = accuracy_val\n",
    "\n",
    "            # save model\n",
    "            net.save(model_file_name)\n",
    "            print(\"üíæ New best model saved!\")\n",
    "\n",
    "            # save stats\n",
    "            with open(stat_file_name, \"w\", encoding=\"utf-8\") as stat_file:\n",
    "                # indent makes json pretty\n",
    "                json.dump(stats, stat_file, indent=4)\n",
    "\n",
    "        print(\n",
    "            f'Epoch {stats[\"total_epochs\"]}: Loss {avg_loss:.4f}, Training Accuracy {accuracy:.2f}%, Val Accuracy {accuracy_val:.2f}%')\n",
    "\n",
    "    # load best model found\n",
    "    net.load(model_file_name)\n",
    "    net.to(device)\n",
    "\n",
    "    # TEST LOOP (after training)\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for events, labels in test_dl:\n",
    "            events, labels = events.to(device), labels.to(device)\n",
    "            output, _, _ = net(events)\n",
    "\n",
    "            out = output[:, skip_window:, :].mean(\n",
    "                dim=1)  # using skip and mean value vmem\n",
    "\n",
    "            predicted = torch.argmax(out, 1).to(device)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy_test = (correct/total)*100\n",
    "        stats['test_acc'] = accuracy_test\n",
    "\n",
    "        if (stats['test_acc'] > best_stat[\"test_acc\"]):\n",
    "            with open(bestStat_file_name, \"w\", encoding=\"utf-8\") as stat_file:\n",
    "                # indent makes json pretty\n",
    "                json.dump(stats, stat_file, indent=4)\n",
    "                # save model\n",
    "                net.save(bestModel_file_name)\n",
    "                print(\"üíæ Record breaking model saved!\")\n",
    "\n",
    "    print(f\"Test Accuracy: {accuracy_test:.3f}%\")\n",
    "\n",
    "\n",
    "# ---------------- Program Start---------------------#\n",
    "# %%\n",
    "stat_file_name = \"New_Stats.json\"\n",
    "model_file_name = \"New_Model.json\"\n",
    "bestStat_file_name = \"Best_Stats.json\"\n",
    "bestModel_file_name = \"Best_Model.json\"\n",
    "# %%\n",
    "# load model if save exists.\n",
    "if os.path.exists(os.path.join(dir, model_file_name)):\n",
    "    net.load(model_file_name)\n",
    "    net.to(device)\n",
    "# load statistics if save exists\n",
    "if os.path.exists(os.path.join(dir, stat_file_name)):\n",
    "    with open(stat_file_name, \"r\", encoding=\"utf-8\") as stat_file:\n",
    "        stats = json.load(stat_file)\n",
    "# load best stats if save exists\n",
    "if os.path.exists(os.path.join(dir, bestStat_file_name)):\n",
    "    with open(bestStat_file_name, \"r\", encoding=\"utf-8\") as stat_file:\n",
    "        best_stat = json.load(stat_file)\n",
    "\n",
    "trainModel = True\n",
    "\n",
    "if trainModel:\n",
    "    # lol train\n",
    "    train(net, train_dl, val_dl, test_dl)\n",
    "else:\n",
    "    # %%\n",
    "    import matplotlib.pyplot as plt\n",
    "    import json\n",
    "    import os\n",
    "    dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "    stats = {}\n",
    "\n",
    "    if os.path.exists(os.path.join(dir, stat_file_name)):\n",
    "        with open(stat_file_name, \"r\", encoding=\"utf-8\") as stat_file:\n",
    "            stats = json.load(stat_file)\n",
    "\n",
    "    # show stats\n",
    "    epochs = list(range(stats[\"total_epochs\"]+1))\n",
    "\n",
    "    # Accuracy Curve\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, stats[\"train_acc_list\"], label='Train Accuracy')\n",
    "    plt.plot(epochs, stats[\"val_acc_list\"], label='Val Accuracy')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.title(\"Accuracy Curve\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Loss Curve\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, stats[\"train_loss_list\"], label='Train Loss')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training Loss Curve\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(\"plots\", \"lastestDataset\"))\n",
    "    plt.show()\n",
    "\n",
    "    # with our trainned net make a predicition on a file\n",
    "    '''\n",
    "    events, label = train_data[4]\n",
    "\n",
    "    out, _, rd = net(events, record = True)\n",
    "\n",
    "    time, channels = torch.where(out[0])\n",
    "\n",
    "    #plot predition.\n",
    "    plt.plot(time * net_dt, channels, '|')\n",
    "    plt.xlim([0,1])\n",
    "    plt.ylim([-1,3])\n",
    "    plt.plot(0.01, label, '>', ms=18) #show highlight correct label on plot\n",
    "    plt.show()\n",
    "    '''\n",
    "# %%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
